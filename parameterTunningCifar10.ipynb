{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QghFK8f9SY0_",
    "outputId": "86936bed-acc5-482e-c3d3-8bfc86333463"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./CVAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sImqpIA_Si3m",
    "outputId": "87b80760-6210-4a07-c6c3-fc7c3a56fc8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyro-ppl in /opt/conda/lib/python3.11/site-packages (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/lib/python3.11/site-packages (from pyro-ppl) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.11/site-packages (from pyro-ppl) (3.4.0)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from pyro-ppl) (0.1.2)\n",
      "Requirement already satisfied: torch>=2.0 in /opt/conda/lib/python3.11/site-packages (from pyro-ppl) (2.1.2+cu121)\n",
      "Requirement already satisfied: tqdm>=4.36 in /opt/conda/lib/python3.11/site-packages (from pyro-ppl) (4.66.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->pyro-ppl) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->pyro-ppl) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->pyro-ppl) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->pyro-ppl) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->pyro-ppl) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->pyro-ppl) (2024.9.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->pyro-ppl) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0->pyro-ppl) (3.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=2.0->pyro-ppl) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyro-ppl\n",
    "from main import main\n",
    "import argparse\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with lr=0.001, num_epochs=2, num_particles=20, z_dim=500, hidden_1=500, hidden_2=1000\n",
      "Device:  cuda:0\n",
      "Training with 1 quadrant as input...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Epoch 0 train    : 100%|██████████| 391/391 [00:11<00:00, 34.84it/s, early_stop_count=0, loss=1536.36]\n",
      "NN Epoch 0 val      : 100%|██████████| 79/79 [00:01<00:00, 46.70it/s, early_stop_count=0, loss=1524.78]\n",
      "NN Epoch 1 train    : 100%|██████████| 391/391 [00:10<00:00, 36.01it/s, early_stop_count=0, loss=1510.63]\n",
      "NN Epoch 1 val      : 100%|██████████| 79/79 [00:01<00:00, 47.96it/s, early_stop_count=0, loss=1625.99]\n",
      "CVAE Epoch 0 train  : 100%|██████████| 391/391 [00:17<00:00, 21.97it/s, early_stop_count=0, loss=1501.30]\n",
      "CVAE Epoch 0 val    : 100%|██████████| 79/79 [00:02<00:00, 38.65it/s, early_stop_count=0, loss=1476.12]\n",
      "CVAE Epoch 1 train  : 100%|██████████| 391/391 [00:17<00:00, 22.07it/s, early_stop_count=0, loss=1474.01]\n",
      "CVAE Epoch 1 val    : 100%|██████████| 79/79 [00:02<00:00, 39.31it/s, early_stop_count=0, loss=1474.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.0..1.0].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|██████████| 313/313 [00:52<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df:                         1 quadrant\n",
      "NN (baseline)       110951.534095\n",
      "CVAE (Monte Carlo)    1474.139379\n",
      "Columns:  ['1 quadrant']\n",
      "Training with 2 quadrants as input...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Epoch 0 train    : 100%|██████████| 391/391 [00:10<00:00, 35.94it/s, early_stop_count=0, loss=990.85] \n",
      "NN Epoch 0 val      : 100%|██████████| 79/79 [00:01<00:00, 45.96it/s, early_stop_count=0, loss=978.51]\n",
      "NN Epoch 1 train    : 100%|██████████| 391/391 [00:10<00:00, 35.93it/s, early_stop_count=0, loss=971.30]\n",
      "NN Epoch 1 val      : 100%|██████████| 79/79 [00:01<00:00, 46.81it/s, early_stop_count=0, loss=973.02]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError with configuration lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, num_epochs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_ep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, num_particles=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_part\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, z_dim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, hidden_1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhid1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, hidden_2=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhid2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/lectures/194.150-2024W/CVAE/Probabilistic-Programming-and-AI/./CVAE/main.py:75\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     71\u001b[0m     baseline_net \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseline_net_q\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(num_quadrant_inputs)\n\u001b[1;32m     73\u001b[0m     )\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     baseline_net \u001b[38;5;241m=\u001b[39m \u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stop_patience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbaseline_net_q\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_quadrant_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Train CVAE\u001b[39;00m\n\u001b[1;32m     90\u001b[0m cvae_net \u001b[38;5;241m=\u001b[39m cvae\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m     91\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     92\u001b[0m     dataloaders\u001b[38;5;241m=\u001b[39mdataloaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m     pretrained\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mpretrained\n\u001b[1;32m    110\u001b[0m )\n",
      "File \u001b[0;32m~/lectures/194.150-2024W/CVAE/Probabilistic-Programming-and-AI/./CVAE/baseline.py:234\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(device, dataloaders, dataset_sizes, learning_rate, num_epochs, early_stop_patience, model_path, dataset, hidden_1, hidden_2, pretrained)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# Save model weights\u001b[39;00m\n\u001b[1;32m    233\u001b[0m Path(model_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 234\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m baseline_net\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:618\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    615\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    619\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:492\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/serialization.py:463\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the hyperparameter search space\n",
    "lr = [1e-3, 1e-3]\n",
    "num_epochs = [2, 50]\n",
    "num_particl = [20, 10]\n",
    "z = [500] #, 250 makla\n",
    "hidd1 = [500]  # Around the current hidden_1=500, 400, 500, makla\n",
    "hidd2 = [1000]  # Around the current hidden_2=500\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for lr, num_ep, num_part, z, hid1, hid2 in itertools.product(lr, num_epochs, num_particl, z, hidd1, hidd2):\n",
    "    # Set up arguments\n",
    "    args = argparse.Namespace(\n",
    "        num_quadrant_inputs=[1, 2, 3],\n",
    "        num_epochs=num_ep,\n",
    "        early_stop_patience=3,\n",
    "        learning_rate=lr,\n",
    "        cuda=True,\n",
    "        num_images=10,\n",
    "        num_samples=10,\n",
    "        num_particles=num_part,\n",
    "        dataset='cifar10',\n",
    "        z_dim=z,\n",
    "        hidden_1=hid1,\n",
    "        hidden_2=hid2,\n",
    "        random_mask=False,\n",
    "        allow_baseline_reuse=False,\n",
    "        use_conv=False,\n",
    "        pretrained=True\n",
    "    )\n",
    "\n",
    "    # Log the current configuration\n",
    "    print(f\"Running with lr={lr}, num_epochs={num_ep}, num_particles={num_part}, z_dim={z}, hidden_1={hid1}, hidden_2={hid2}\")\n",
    "\n",
    "    # Run the main function\n",
    "    try:\n",
    "        main(args)\n",
    "    except Exception as e:\n",
    "        print(f\"Error with configuration lr={lr}, num_epochs={num_ep}, num_particles={num_part}, z_dim={z}, hidden_1={hid1}, hidden_2={hid2}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Save the results\n",
    "    if os.path.exists(\"results.csv\"):\n",
    "        output_file = f\"CVAE/tuning_results_cifar10_pretrained/csvs/results_lr_{lr}_epochs_{num_ep}_particles_{num_part}_z_{z}_h1_{hid1}_h2_{hid2}.csv\"\n",
    "        shutil.copy(\"results.csv\", output_file)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "    else:\n",
    "        print(f\"No 'results.csv' file generated for lr={lr}, num_epochs={num_ep}, num_particles={num_part}, z_dim={z}, hidden_1={hid1}, hidden_2={hid2}.\")\n",
    "\n",
    "    # Backup important files before starting\n",
    "    for q in range(1, 4):\n",
    "        plot_file = f\"cvae_plot_q{q}.png\"\n",
    "        if os.path.exists(plot_file):\n",
    "            output_file = f\"CVAE/tuning_results_cifar10_pretrained/images/cvae_plot_q{q}_lr_{lr}_epochs_{num_ep}_particles_{num_part}_z_{z}_h1_{hid1}_h2_{hid2}.png\"\n",
    "            shutil.copy(plot_file, output_file)\n",
    "            print(f\"Backup created for '{plot_file}' as '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kouYN9f0SoIJ",
    "outputId": "a2145289-a9e6-4074-be01-f275f5f3ccff"
   },
   "outputs": [],
   "source": [
    "# Combine all results for analysis\n",
    "result_files = glob.glob(\"CVAE/tuning_results_cifar10_pretrained/csvs/*.csv\")\n",
    "if result_files:\n",
    "    combined_results = []\n",
    "\n",
    "    for file in result_files:\n",
    "        # Read each result file\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        # Rename the first column if necessary\n",
    "        if 'Unnamed: 0' in df.columns:\n",
    "            df.rename(columns={'Unnamed: 0': 'Method'}, inplace=True)\n",
    "\n",
    "        print(df)\n",
    "\n",
    "        # Extract performance gaps and compute the aggregate gap\n",
    "        # Extract performance gaps and compute the aggregate gap\n",
    "        performance_gap_row = df.loc[df['Method'] == 'Performance gap']\n",
    "        aggregate_gap = performance_gap_row[['1 quadrant', '2 quadrants', '3 quadrants']].sum(axis=1).values[0]\n",
    "\n",
    "        # Store results with the file name and aggregate gap\n",
    "        combined_results.append({\n",
    "            \"file\": file,\n",
    "            \"aggregate_gap\": aggregate_gap,\n",
    "            \"1 quadrant gap\": performance_gap_row['1 quadrant'].values[0],\n",
    "            \"2 quadrants gap\": performance_gap_row['2 quadrants'].values[0],\n",
    "            \"3 quadrants gap\": performance_gap_row['3 quadrants'].values[0]\n",
    "        })\n",
    "\n",
    "    # Convert to a DataFrame for sorting and analysis\n",
    "    combined_results_df = pd.DataFrame(combined_results)\n",
    "\n",
    "    # Sort by aggregate gap in descending order (largest gap first)\n",
    "    combined_results_df = combined_results_df.sort_values(by=\"aggregate_gap\", ascending=False)\n",
    "\n",
    "    # Save the combined results to a file\n",
    "    combined_results_df.to_csv(\"CVAE/tuning_results_cifar10_pretrained/combined_results.csv\", index=False)\n",
    "    print(\"All results combined and saved to 'CVAE/tuning_results_cifar10_pretrained/combined_results.csv'.\")\n",
    "\n",
    "    # Display the best configuration\n",
    "    print(\"Best configuration:\")\n",
    "    best_file = combined_results_df.iloc[0]['file']\n",
    "    print(f\"File: {best_file}, Aggregate Performance Gap: {combined_results_df.iloc[0]['aggregate_gap']}\")\n",
    "\n",
    "    # Optionally, load and display the details of the best result\n",
    "    best_result = pd.read_csv(best_file)\n",
    "    print(\"\\nDetails of the best configuration:\")\n",
    "    print(best_result)\n",
    "else:\n",
    "    print(\"No results to combine.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTelD3I3Sqgt",
    "outputId": "378d6170-38f7-47df-9423-a538b035bdcb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
